{
    "seed": 1234,
    "dataset": "billiard_irr",
    "max_time_scale": 100,
    "time_enc_dim": 8,
    "batch_size": 2048,
    "att_dims": 128,
    "model_dims": 1024,
    "inner_dims": 2048,
    "dropout": 0.0,
    "n_heads": 12,
    "n_layers": 8, 
    "epochs": 1000000,
    "clip": 0.01,
    "data_root": "./data/",
    "lr": 1e-4,
    "layer_norm": 0,
    "resume_from_epoch": -1,
    "use_gap_encoding": 0,
    "exp_dir": "./log/per_gap_8_layer_12_heads_no_dropout_unnormalize_max_level_4_mse_0.975_miss_irr_att_d_128_model_d_1024_large_train",
    "pretrained": 0,
    "mercer": 0,
    "adapter": 0,
    "att_mask": 1,
    "max_level": 4,
    "time_dim": 72,
    "expand_dim": 5,
    "save_every": 10,
    "model_name": "Encoder",
    "normalize": 0,
    "confidence": 0,
    "use_ta": 1,
    "gp": 0,
    "weight_decay": 0
}
